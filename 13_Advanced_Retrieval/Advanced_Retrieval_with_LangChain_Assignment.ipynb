{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-IqJAMkwnCF"
      },
      "source": [
        "# Advanced Retrieval with LangChain\n",
        "\n",
        "In the following notebook, we'll explore various methods of advanced retrieval using LangChain!\n",
        "\n",
        "We'll touch on:\n",
        "\n",
        "- Naive Retrieval\n",
        "- Best-Matching 25 (BM25)\n",
        "- Multi-Query Retrieval\n",
        "- Parent-Document Retrieval\n",
        "- Contextual Compression (a.k.a. Rerank)\n",
        "- Ensemble Retrieval\n",
        "- Semantic chunking\n",
        "\n",
        "We'll also discuss how these methods impact performance on our set of documents with a simple RAG chain.\n",
        "\n",
        "There will be two breakout rooms:\n",
        "\n",
        "- ðŸ¤ Breakout Room Part #1\n",
        "  - Task 1: Getting Dependencies!\n",
        "  - Task 2: Data Collection and Preparation\n",
        "  - Task 3: Setting Up QDrant!\n",
        "  - Task 4-10: Retrieval Strategies\n",
        "- ðŸ¤ Breakout Room Part #2\n",
        "  - Activity: Evaluate with Ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rKP3hgHivpe"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xes8oT-xHN7"
      },
      "source": [
        "## Task 1: Getting Dependencies!\n",
        "\n",
        "We're going to need a few specific LangChain community packages, like OpenAI (for our [LLM](https://platform.openai.com/docs/models) and [Embedding Model](https://platform.openai.com/docs/guides/embeddings)) and Cohere (for our [Reranker](https://cohere.com/rerank)).\n",
        "\n",
        "> You do not need to run the following cells if you are running this notebook locally. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkgFAXWVW3wm",
        "outputId": "636db35c-f05a-4038-ec7a-02360bef2dae"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain langchain-openai langchain-cohere rank_bm25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKqYM4Eoxcov"
      },
      "source": [
        "We're also going to be leveraging [Qdrant's](https://qdrant.tech/documentation/frameworks/langchain/) (pronounced \"Quadrant\") VectorDB in \"memory\" mode (so we can leverage it locally in our colab environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s6xav5CxYnML"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7OHJXzfyJyA"
      },
      "source": [
        "We'll also provide our OpenAI key, as well as our Cohere API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LttlDQUYgSI",
        "outputId": "9dca95ab-4d02-4adf-ec3f-cb831326dc54"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iUahNiJyQbv",
        "outputId": "78bf06ef-2ee8-46c3-f73d-27958b4dd79b"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0pDRFEWSXvh"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw304iAFyRtl"
      },
      "source": [
        "## Task 2: Data Collection and Preparation\n",
        "\n",
        "We'll be using some reviews from the 4 movies in the John Wick franchise today to explore the different retrieval strategies.\n",
        "\n",
        "These were obtained from IMDB, and are available in the [AIM Data Repository](https://github.com/AI-Maker-Space/DataRepository)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXKHcZmKzDwT"
      },
      "source": [
        "### Data Collection\n",
        "\n",
        "We can simply `wget` these from GitHub.\n",
        "\n",
        "You could use any review data you wanted in this step - just be careful to make sure your metadata is aligned with your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbbSIGtzX3dS",
        "outputId": "0ce6514e-2479-4001-af24-824f987ce599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-03-01 17:50:25--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19628 (19K) [text/plain]\n",
            "Saving to: â€˜john_wick_1.csvâ€™\n",
            "\n",
            "john_wick_1.csv     100%[===================>]  19.17K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-03-01 17:50:25 (6.11 MB/s) - â€˜john_wick_1.csvâ€™ saved [19628/19628]\n",
            "\n",
            "--2025-03-01 17:50:26--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14747 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_2.csvâ€™\n",
            "\n",
            "john_wick_2.csv     100%[===================>]  14.40K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-03-01 17:50:26 (5.37 MB/s) - â€˜john_wick_2.csvâ€™ saved [14747/14747]\n",
            "\n",
            "--2025-03-01 17:50:26--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13888 (14K) [text/plain]\n",
            "Saving to: â€˜john_wick_3.csvâ€™\n",
            "\n",
            "john_wick_3.csv     100%[===================>]  13.56K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2025-03-01 17:50:26 (6.20 MB/s) - â€˜john_wick_3.csvâ€™ saved [13888/13888]\n",
            "\n",
            "--2025-03-01 17:50:26--  https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15109 (15K) [text/plain]\n",
            "Saving to: â€˜john_wick_4.csvâ€™\n",
            "\n",
            "john_wick_4.csv     100%[===================>]  14.75K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2025-03-01 17:50:26 (4.22 MB/s) - â€˜john_wick_4.csvâ€™ saved [15109/15109]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw1.csv -O john_wick_1.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw2.csv -O john_wick_2.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw3.csv -O john_wick_3.csv\n",
        "!wget https://raw.githubusercontent.com/AI-Maker-Space/DataRepository/main/jw4.csv -O john_wick_4.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A92NC2QZzCsi"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We want to make sure all our documents have the relevant metadata for the various retrieval strategies we're going to be applying today.\n",
        "\n",
        "- Self-Query: Wants as much metadata as we can provide\n",
        "- Time-weighted: Wants temporal data\n",
        "\n",
        "> NOTE: While we're creating a temporal relationship based on when these movies came out for illustrative purposes, it needs to be clear that the \"time-weighting\" in the Time-weighted Retriever is based on when the document was *accessed* last - not when it was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GshBjVRJZ6p8"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "documents = []\n",
        "\n",
        "for i in range(1, 5):\n",
        "  loader = CSVLoader(\n",
        "      file_path=f\"john_wick_{i}.csv\",\n",
        "      metadata_columns=[\"Review_Date\", \"Review_Title\", \"Review_Url\", \"Author\", \"Rating\"]\n",
        "  )\n",
        "\n",
        "  movie_docs = loader.load()\n",
        "  for doc in movie_docs:\n",
        "\n",
        "    # Add the \"Movie Title\" (John Wick 1, 2, ...)\n",
        "    doc.metadata[\"Movie_Title\"] = f\"John Wick {i}\"\n",
        "\n",
        "    # convert \"Rating\" to an `int`, if no rating is provided - assume 0 rating\n",
        "    doc.metadata[\"Rating\"] = int(doc.metadata[\"Rating\"]) if doc.metadata[\"Rating\"] else 0\n",
        "\n",
        "    # newer movies have a more recent \"last_accessed_at\"\n",
        "    doc.metadata[\"last_accessed_at\"] = datetime.now() - timedelta(days=4-i)\n",
        "\n",
        "  documents.extend(movie_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gQphb6y0C0S"
      },
      "source": [
        "Let's look at an example document to see if everything worked as expected!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUkCf7DaMiq",
        "outputId": "e90bd5da-1d87-423b-838a-cb6efc16b199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'john_wick_1.csv', 'row': 0, 'Review_Date': '6 May 2015', 'Review_Title': ' Kinetic, concise, and stylish; John Wick kicks ass.\\n', 'Review_Url': '/review/rw3233896/?ref_=tt_urv', 'Author': 'lnvicta', 'Rating': 8, 'Movie_Title': 'John Wick 1', 'last_accessed_at': datetime.datetime(2025, 2, 26, 17, 50, 27, 386953)}, page_content=\": 0\\nReview: The best way I can describe John Wick is to picture Taken but instead of Liam Neeson it's Keanu Reeves and instead of his daughter it's his dog. That's essentially the plot of the movie. John Wick (Reeves) is out to seek revenge on the people who took something he loved from him. It's a beautifully simple premise for an action movie - when action movies get convoluted, they get bad i.e. A Good Day to Die Hard. John Wick gives the viewers what they want: Awesome action, stylish stunts, kinetic chaos, and a relatable hero to tie it all together. John Wick succeeds in its simplicity.\")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWaQpdHl0Gzc"
      },
      "source": [
        "## Task 3: Setting up QDrant!\n",
        "\n",
        "Now that we have our documents, let's create a QDrant VectorStore with the collection name \"JohnWick\".\n",
        "\n",
        "We'll leverage OpenAI's [`text-embedding-3-small`](https://openai.com/blog/new-embedding-models-and-api-updates) because it's a very powerful (and low-cost) embedding model.\n",
        "\n",
        "> NOTE: We'll be creating additional vectorstores where necessary, but this pattern is still extremely useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NT8ihRJbYmMT"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import Qdrant\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "vectorstore = Qdrant.from_documents(\n",
        "    documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWick\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x2SS4Rh0hiN"
      },
      "source": [
        "## Task 4: Naive RAG Chain\n",
        "\n",
        "Since we're focusing on the \"R\" in RAG today - we'll create our Retriever first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEH7X5Ai08FH"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "This naive retriever will simply look at each review as a document, and use cosine-similarity to fetch the 10 most relevant documents.\n",
        "\n",
        "> NOTE: We're choosing `10` as our `k` here to provide enough documents for our reranking process later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GFDPrNBtb72o"
      },
      "outputs": [],
      "source": [
        "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbBhyQjz06dx"
      },
      "source": [
        "### A - Augmented\n",
        "\n",
        "We're going to go with a standard prompt for our simple RAG chain today! Nothing fancy here, we want this to mostly be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7uSz-Dbqcoki"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_TEMPLATE = \"\"\"\\\n",
        "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
        "\n",
        "If you do not know the answer, or are unsure, say you don't know.\n",
        "\n",
        "Query:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlRzpb231GGJ"
      },
      "source": [
        "### G - Generation\n",
        "\n",
        "We're going to leverage `gpt-3.5-turbo` as our LLM today, as - again - we want this to largely be about the Retrieval process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "c-1t9H60dJLg"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mg3QRGzA1M2x"
      },
      "source": [
        "### LCEL RAG Chain\n",
        "\n",
        "We're going to use LCEL to construct our chain.\n",
        "\n",
        "> NOTE: This chain will be exactly the same across the various examples with the exception of our Retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0bvstS7mdOW3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "naive_retrieval_chain = (\n",
        "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
        "    # \"question\" : populated by getting the value of the \"question\" key\n",
        "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
        "    {\"context\": itemgetter(\"question\") | naive_retriever, \"question\": itemgetter(\"question\")}\n",
        "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
        "    #              by getting the value of the \"context\" key from the previous step\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
        "    #              into the LLM and stored in a key called \"response\"\n",
        "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izKujhNb1ZG8"
      },
      "source": [
        "Let's see how this simple chain does on a few different prompts.\n",
        "\n",
        "> NOTE: You might think that we've cherry picked prompts that showcase the individual skill of each of the retrieval strategies - you'd be correct!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LI-5ueEddku9",
        "outputId": "7f3cec18-5f4e-41bb-cf71-51ba0be5388e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked John Wick.'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "43zdcdUydtXh",
        "outputId": "db874e67-f568-4ed1-b863-b7c17b387052"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10 for the movie \"John Wick 3\". Here is the URL to that review: \\'/review/rw4854296/?ref_=tt_urv\\'.'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "lpG6rlvvvKFq",
        "outputId": "a1b330b0-628e-41be-d829-9c1d55e781f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In \"John Wick,\" the storyline follows an ex-hit-man who comes out of retirement to seek vengeance against the gangsters who killed his dog and took everything from him. The film is filled with action-packed shootouts, breathtaking fights, and a suspenseful story of revenge and redemption.'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "naive_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsbfQmbr1leg"
      },
      "source": [
        "Overall, this is not bad! Let's see if we can make it better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft1vt8HPR16w"
      },
      "source": [
        "## Task 5: Best-Matching 25 (BM25) Retriever\n",
        "\n",
        "Taking a step back in time - [BM25](https://www.nowpublishers.com/article/Details/INR-019) is based on [Bag-Of-Words](https://en.wikipedia.org/wiki/Bag-of-words_model) which is a sparse representation of text.\n",
        "\n",
        "In essence, it's a way to compare how similar two pieces of text are based on the words they both contain.\n",
        "\n",
        "This retriever is very straightforward to set-up! Let's see it happen down below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qdF4wuj5R-cG"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIjJlBQ8drKH"
      },
      "source": [
        "We'll construct the same chain - only changing the retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WR15EQG7SLuw"
      },
      "outputs": [],
      "source": [
        "bm25_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | bm25_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gi-yXCDdvJk"
      },
      "source": [
        "Let's look at the responses!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "oY9qzmm3SOrF",
        "outputId": "4d4f450f-5978-460f-f242-b32407868353"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People's opinions on John Wick seem to vary. Some loved the action sequences, the world-building, and Keanu Reeves' performance, while others found the movie lacking in substance, plot, and character development. So, it really depends on individual preferences whether people generally liked John Wick or not.\""
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "igfinyneSQkh",
        "outputId": "9752d4a9-dd16-45b1-f63f-a76e93a05eb3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review: https://www.imdb.com/review/rw8946038/?ref_=tt_urv'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "w0H7pV_USSMQ",
        "outputId": "bdead654-3109-4143-9a30-e1d6ca8dc534"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'John Wick is a movie known for its beautifully choreographed action scenes and emotional setup. It features Keanu Reeves in the lead role. If you love action movies, you will enjoy this film.'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bm25_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvg5xHaUdxCl"
      },
      "source": [
        "It's not clear that this is better or worse - but the `I don't know` isn't great!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-dcbFn2vpZF"
      },
      "source": [
        "## Task 6: Contextual Compression (Using Reranking)\n",
        "\n",
        "Contextual Compression is a fairly straightforward idea: We want to \"compress\" our retrieved context into just the most useful bits.\n",
        "\n",
        "There are a few ways we can achieve this - but we're going to look at a specific example called reranking.\n",
        "\n",
        "The basic idea here is this:\n",
        "\n",
        "- We retrieve lots of documents that are very likely related to our query vector\n",
        "- We \"compress\" those documents into a smaller set of *more* related documents using a reranking algorithm.\n",
        "\n",
        "We'll be leveraging Cohere's Rerank model for our reranker today!\n",
        "\n",
        "All we need to do is the following:\n",
        "\n",
        "- Create a basic retriever\n",
        "- Create a compressor (reranker, in this case)\n",
        "\n",
        "That's it!\n",
        "\n",
        "Let's see it in the code below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "psHvO2K1v_ZQ"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "compressor = CohereRerank(model=\"rerank-english-v3.0\")\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=naive_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TA9RB2x-j7P"
      },
      "source": [
        "Let's create our chain again, and see how this does!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1BXqmxvHwX6T"
      },
      "outputs": [],
      "source": [
        "contextual_compression_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | compression_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V3iGpokswcBb",
        "outputId": "f15d2aa1-5e8b-417d-f623-eb835d072e59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, people generally liked John Wick based on the reviews provided in the context.'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "7u_k0i4OweUd",
        "outputId": "be5fccc8-2352-4189-c524-bbeaa28cf799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10. Here is the URL to that review: \"/review/rw4854296/?ref_=tt_urv\"'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zn1EqaGqweXN",
        "outputId": "42bc5972-4164-46eb-f49d-4272f39bb89b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, after resolving issues with the Russian mafia, John Wick refuses to help a mobster named Santino D'Antonio. In retaliation, Santino blows up Wick's house. Wick then meets with Winston, the owner of the Continental hotel in New York City, who tells him he must honor the marker given by Santino. Santino asks Wick to kill his sister in Rome so he can take her place in criminal organizations. After completing the assignment, Santino puts a seven-million dollar contract on Wick, leading to professional killers coming after him. Wick decides to seek revenge on Santino.\""
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contextual_compression_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEbT0g2S-mZ4"
      },
      "source": [
        "We'll need to rely on something like Ragas to help us get a better sense of how this is performing overall - but it \"feels\" better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqbghrBEQNn5"
      },
      "source": [
        "## Task 7: Multi-Query Retriever\n",
        "\n",
        "Typically in RAG we have a single query - the one provided by the user.\n",
        "\n",
        "What if we had....more than one query!\n",
        "\n",
        "In essence, a Multi-Query Retriever works by:\n",
        "\n",
        "1. Taking the original user query and creating `n` number of new user queries using an LLM.\n",
        "2. Retrieving documents for each query.\n",
        "3. Using all unique retrieved documents as context\n",
        "\n",
        "So, how is it to set-up? Not bad! Let's see it down below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "pfM26ReXQjzU"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=naive_retriever, llm=chat_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "1vRc129jQ5WW"
      },
      "outputs": [],
      "source": [
        "multi_query_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | multi_query_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CGgNuOb3Q3M9",
        "outputId": "c5273ecf-da35-40b8-fbdb-0f8beab425f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, people generally liked John Wick. The reviews highlight the slickness of Keanu Reeves' performance, the brilliance of the action sequences, and the overall entertainment value of the film.\""
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aAlSthxrRDBC",
        "outputId": "230ff807-23ae-4d25-8d11-cfdbed0b77cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Yes, there is one review with a rating of 10. Here is the URL to that review:\\n- '/review/rw4854296/?ref_=tt_urv'\""
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "Uv1mpCK8REs4",
        "outputId": "00fbc22a-ed9b-4613-9695-0b179e3f8369"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'In \"John Wick,\" the main character, John Wick, a retired assassin, comes out of retirement when someone kills his dog. This event sets off a chain of events that involve a lot of carnage and revenge. John Wick is forced back into the world of assassins, facing off against various enemies while trying to settle old debts and protect himself.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multi_query_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDEawBf_d_3G"
      },
      "source": [
        "## Task 8: Parent Document Retriever\n",
        "\n",
        "A \"small-to-big\" strategy - the Parent Document Retriever works based on a simple strategy:\n",
        "\n",
        "1. Each un-split \"document\" will be designated as a \"parent document\" (You could use larger chunks of document as well, but our data format allows us to consider the overall document as the parent chunk)\n",
        "2. Store those \"parent documents\" in a memory store (not a VectorStore)\n",
        "3. We will chunk each of those documents into smaller documents, and associate them with their respective parents, and store those in a VectorStore. We'll call those \"child chunks\".\n",
        "4. When we query our Retriever, we will do a similarity search comparing our query vector to the \"child chunks\".\n",
        "5. Instead of returning the \"child chunks\", we'll return their associated \"parent chunks\".\n",
        "\n",
        "Okay, maybe that was a few steps - but the basic idea is this:\n",
        "\n",
        "- Search for small documents\n",
        "- Return big documents\n",
        "\n",
        "The intuition is that we're likely to find the most relevant information by limiting the amount of semantic information that is encoded in each embedding vector - but we're likely to miss relevant surrounding context if we only use that information.\n",
        "\n",
        "Let's start by creating our \"parent documents\" and defining a `RecursiveCharacterTextSplitter`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qJ53JJuMd_ZH"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "parent_docs = documents\n",
        "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOpXfVUH3gL3"
      },
      "source": [
        "We'll need to set up a new QDrant vectorstore - and we'll use another useful pattern to do so!\n",
        "\n",
        "> NOTE: We are manually defining our embedding dimension, you'll need to change this if you're using a different embedding model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzFc-_9HlGQ-",
        "outputId": "223662dd-c36f-42f7-d1b0-b086e571484e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/xp/fw_gm3jn2xq5ngzrpc74m4lm0000gn/T/ipykernel_53412/3574430551.py:8: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  parent_document_vectorstore = Qdrant(\n"
          ]
        }
      ],
      "source": [
        "client = QdrantClient(location=\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"full_documents\",\n",
        "    vectors_config=models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
        ")\n",
        "\n",
        "parent_document_vectorstore = Qdrant(\n",
        "    collection_name=\"full_documents\", embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\"), client=client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf_g95FA3s6w"
      },
      "source": [
        "Now we can create our `InMemoryStore` that will hold our \"parent documents\" - and build our retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "BpWVjPf4fLUp"
      },
      "outputs": [],
      "source": [
        "store = InMemoryStore()\n",
        "\n",
        "parent_document_retriever = ParentDocumentRetriever(\n",
        "    vectorstore = parent_document_vectorstore,\n",
        "    docstore=store,\n",
        "    child_splitter=child_splitter,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoYmSWfE32Zo"
      },
      "source": [
        "By default, this is empty as we haven't added any documents - let's add some now!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "iQ2ZzfKigMZc"
      },
      "outputs": [],
      "source": [
        "parent_document_retriever.add_documents(parent_docs, ids=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI7Tip1335rE"
      },
      "source": [
        "We'll create the same chain we did before - but substitute our new `parent_document_retriever`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Qq_adt2KlSqp"
      },
      "outputs": [],
      "source": [
        "parent_document_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | parent_document_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNolUVQb4Apt"
      },
      "source": [
        "Let's give it a whirl!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "TXB5i89Zly5W",
        "outputId": "94c240be-7c5b-4c58-9eee-56d93285a054"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"People's opinions on John Wick seem to be divided based on the reviews provided. Some people really enjoy the series and find it consistent and well-received, while others have strong negative opinions about it. So, it seems like whether people generally like John Wick or not depends on individual preferences.\""
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "V5F1T-wNl3cg",
        "outputId": "9b81e72e-5db7-4b8a-b25b-400ea0df5335"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10 for the movie \"John Wick 3.\" The URL to that review is: \\'/review/rw4854296/?ref_=tt_urv\\'.'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZqARszGzvGcG",
        "outputId": "8867f83c-db13-4db4-d57f-9bd51d32cd8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, a retired assassin named John Wick seeks vengeance after his dog is killed and his car is stolen. He gets dragged into a task to pay off an old debt by helping to take over the Assassin's Guild in Italy, Canada, and Manhattan, which leads to him killing many assassins.\""
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parent_document_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B41cj42s4DPM"
      },
      "source": [
        "Overall, the performance *seems* largely the same. We can leverage a tool like [Ragas]() to more effectively answer the question about the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUrIBKl_TwS9"
      },
      "source": [
        "## Task 9: Ensemble Retriever\n",
        "\n",
        "In brief, an Ensemble Retriever simply takes 2, or more, retrievers and combines their retrieved documents based on a rank-fusion algorithm.\n",
        "\n",
        "In this case - we're using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm.\n",
        "\n",
        "Setting it up is as easy as providing a list of our desired retrievers - and the weights for each retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8j7jpZsKTxic"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "retriever_list = [bm25_retriever, naive_retriever, parent_document_retriever, compression_retriever, multi_query_retriever]\n",
        "equal_weighting = [1/len(retriever_list)] * len(retriever_list)\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retriever_list, weights=equal_weighting\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpo9Psl5hhJ-"
      },
      "source": [
        "We'll pack *all* of these retrievers together in an ensemble."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KZ__EZwpUKkd"
      },
      "outputs": [],
      "source": [
        "ensemble_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsvHpRMj24L"
      },
      "source": [
        "Let's look at our results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lMvqL88UQI-",
        "outputId": "d86dd5f7-0a13-4836-c0ce-cc4c431fd889"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Based on the context provided from various reviews of John Wick movies, it seems that John Wick received positive reviews overall. The general sentiment is that people enjoyed the movies for their action sequences, Keanu Reeves' performance, the choreography, and the unique world the movies create. Most reviews praise the film for being fun, slick, and filled with stylish action scenes, making it a must-see for action fans. Therefore, it can be concluded that people generally liked John Wick.\""
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MNFWLYECURI1",
        "outputId": "b17973b5-66a9-4481-97d5-880b5754b5c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, one review has a rating of 10. Here is the URL to that review:\\n- /review/rw4854296/?ref_=tt_urv'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "A7qbHfWgUR4c",
        "outputId": "f7373144-59ef-4fc7-b75d-ca00e7df881e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'John Wick is an ex-hitman who comes out of retirement to seek vengeance on gangsters who killed his dog and took everything from him. It follows his journey of revenge as he unleashes destruction against those who crossed him, resulting in intense action, shootouts, and thrilling fights.'"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ensemble_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MopbkNJAXVaN"
      },
      "source": [
        "## Task 10: Semantic Chunking\n",
        "\n",
        "While this is not a retrieval method - it *is* an effective way of increasing retrieval performance on corpora that have clean semantic breaks in them.\n",
        "\n",
        "Essentially, Semantic Chunking is implemented by:\n",
        "\n",
        "1. Embedding all sentences in the corpus.\n",
        "2. Combining or splitting sequences of sentences based on their semantic similarity based on a number of [possible thresholding methods](https://python.langchain.com/docs/how_to/semantic-chunker/):\n",
        "  - `percentile`\n",
        "  - `standard_deviation`\n",
        "  - `interquartile`\n",
        "  - `gradient`\n",
        "3. Each sequence of related sentences is kept as a document!\n",
        "\n",
        "Let's see how to implement this!\n",
        "\n",
        "> NOTE: You do not need to run this cell if you're running this locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHeB-yGXneL",
        "outputId": "efc59105-518a-4134-9228-d98b8a97e08e"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain_experimental"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9ciZbFEldv_"
      },
      "source": [
        "We'll use the `percentile` thresholding method for this example which will:\n",
        "\n",
        "Calculate all distances between sentences, and then break apart sequences of setences that exceed a given percentile among all distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "66EIEWiEYl5y"
      },
      "outputs": [],
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "semantic_chunker = SemanticChunker(\n",
        "    embeddings,\n",
        "    breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqoKmz12mhRW"
      },
      "source": [
        "Now we can split our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ROcV7o68ZIq7"
      },
      "outputs": [],
      "source": [
        "semantic_documents = semantic_chunker.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8-LNC-Xmjex"
      },
      "source": [
        "Let's create a new vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "h3sl9QjyZhIe"
      },
      "outputs": [],
      "source": [
        "semantic_vectorstore = Qdrant.from_documents(\n",
        "    semantic_documents,\n",
        "    embeddings,\n",
        "    location=\":memory:\",\n",
        "    collection_name=\"JohnWickSemantic\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh_r_-LHmmKn"
      },
      "source": [
        "We'll use naive retrieval for this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "odVyDUHwZftc"
      },
      "outputs": [],
      "source": [
        "semantic_retriever = semantic_vectorstore.as_retriever(search_kwargs={\"k\" : 10})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mkeiv_ojmp6G"
      },
      "source": [
        "Finally we can create our classic chain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "xWE_0J0mZveG"
      },
      "outputs": [],
      "source": [
        "semantic_retrieval_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | semantic_retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5pfjLQ3ms9_"
      },
      "source": [
        "And view the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "0lN2j-e4Z0SD",
        "outputId": "ef483e21-7200-4dfc-b8bf-aed4f23587b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Based on the reviews provided, it seems that the majority of people liked John Wick. Some reviews highlighted the movie as cool, fun, and well-done in terms of action sequences and character development. However, there was one review that mentioned the magic being gone in the third installment of the series. So overall, opinions are generally positive, with a few exceptions.'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Did people generally like John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "xdqfBH1SZ3f9",
        "outputId": "ed62b2d1-7586-46cc-aaf4-c54192a56155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Yes, there is a review with a rating of 10 for \"John Wick 3\". The URL to that review is: \\'/review/rw4854296/?ref_=tt_urv\\''"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"Do any reviews have a rating of 10? If so - can I have the URLs to those reviews?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "rAcAObZnZ4o6",
        "outputId": "3f1cade3-41e4-4e42-ef71-048dd18e5e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"In John Wick, Keanu Reeves plays the character of John Wick, a retired assassin who seeks revenge on the people who took something he loved from him. The initial premise of the movie involves someone killing John's dog, which leads to a series of events culminating in a quest for vengeance against those who wronged him. It is a fast-paced action film with stylish stunts and kinetic chaos that keeps viewers engaged throughout.\""
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "semantic_retrieval_chain.invoke({\"question\" : \"What happened in John Wick?\"})[\"response\"].content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk2n3-pnVWDJ"
      },
      "source": [
        "# ðŸ¤ Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SkJLYwMVZkj"
      },
      "source": [
        "#### ðŸ—ï¸ Activity #1\n",
        "\n",
        "Your task is to evaluate the various Retriever methods against eachother.\n",
        "\n",
        "You are expected to:\n",
        "\n",
        "1. Create a \"golden dataset\"\n",
        " - Use Synthetic Data Generation (powered by Ragas, or otherwise) to create this dataset\n",
        "2. Evaluate each retriever with *retriever specific* Ragas metrics\n",
        " - Semantic Chunking is not considered a retriever method and will not be required for marks, but you may find it useful to do a \"semantic chunking on\" vs. \"semantic chunking off\" comparision between them\n",
        "3. Compile these in a list and write a small paragraph about which is best for this particular data and why.\n",
        "\n",
        "Your analysis should factor in:\n",
        "  - Cost\n",
        "  - Latency\n",
        "  - Performance\n",
        "\n",
        "> NOTE: This is **NOT** required to be completed in class. Please spend time in your breakout rooms creating a plan before moving on to writing code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWAr16a5XMub"
      },
      "source": [
        "##### HINTS:\n",
        "\n",
        "- LangSmith provides detailed information about latency and cost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "** My Code Here **\n",
        "\n",
        "Working on homework 13 and creating a new branch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "tgDICngKXLGK"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"RAGAS_APP_TOKEN\"] = getpass(\"Please enter your Ragas API key!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import ragas\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Create the base models\n",
        "base_llm = ChatOpenAI(model=\"gpt-4\")\n",
        "base_embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Wrap them for ragas\n",
        "generator_llm = LangchainLLMWrapper(langchain_llm=base_llm)\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(embeddings=base_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generating a golden dataset with ragas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]        Node 88d8010a-5c3a-4fde-8561-96112ce822c7 does not have a summary. Skipping filtering.\n",
            "Node 7e0bd6d3-439e-475a-96f3-4e0cd038177f does not have a summary. Skipping filtering.\n",
            "Node e4ca0373-9bcb-4c85-aa66-184fc60f86ef does not have a summary. Skipping filtering.\n",
            "Node fe43b3d3-abac-4c84-ae9f-9ead14f68951 does not have a summary. Skipping filtering.\n",
            "Node 48250f8a-ef6a-49d5-bef4-c3687be08c4f does not have a summary. Skipping filtering.\n",
            "Node 03e4b838-6214-47ca-911d-df5c58c4e1c0 does not have a summary. Skipping filtering.\n",
            "Node 4f273a6e-258b-4ee7-8dff-344332924350 does not have a summary. Skipping filtering.\n",
            "Node 7c3a2ef5-67c5-4b64-ab72-7e09f33cb674 does not have a summary. Skipping filtering.\n",
            "Node 2721cf41-8065-4a5b-bdb5-2f12f9fc063a does not have a summary. Skipping filtering.\n",
            "Node c3bbdeb4-ad4c-43b2-ae49-c404d4730e02 does not have a summary. Skipping filtering.\n",
            "Node f4ed672e-93c7-42cc-b298-75cf965c5136 does not have a summary. Skipping filtering.\n",
            "Node 9235f2e4-a9df-45d2-938f-9d3004c6f767 does not have a summary. Skipping filtering.\n",
            "Node 94f26a10-21cf-4646-bde1-3e953e514e98 does not have a summary. Skipping filtering.\n",
            "Node 3e413254-820e-46a8-b615-7898f336d5f6 does not have a summary. Skipping filtering.\n",
            "Node 3853c7b2-3be8-45e0-8824-d30357df9007 does not have a summary. Skipping filtering.\n",
            "Node 44cb9f70-90a4-4793-aa3e-77aaa08e8685 does not have a summary. Skipping filtering.\n",
            "Node 938e3337-3bc1-4765-a639-a5a576c16f5f does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  17%|â–ˆâ–‹        | 17/100 [00:00<00:03, 26.93it/s]Node 85f5a0a6-af0b-4294-aa6f-e62409287134 does not have a summary. Skipping filtering.\n",
            "Node d96b2999-2659-43ad-9b7b-c35e54e54865 does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  20%|â–ˆâ–ˆ        | 20/100 [00:00<00:03, 25.69it/s]Node 5eac5d89-0cbc-4526-ab4a-82d682bb944c does not have a summary. Skipping filtering.\n",
            "Node 879bf51e-bc80-496e-a6a6-56b86c94be28 does not have a summary. Skipping filtering.\n",
            "Node eddc6d49-7556-44cc-99ed-1a8d9ff3086b does not have a summary. Skipping filtering.\n",
            "Node 296d3950-40c2-4084-afc3-36c9af27f59f does not have a summary. Skipping filtering.\n",
            "Node 367fd6c8-78a1-42c6-83c4-5265e6311085 does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  27%|â–ˆâ–ˆâ–‹       | 27/100 [00:00<00:02, 33.53it/s]Node 8f2408c5-8800-4aed-a6ad-5f643e5bae72 does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:01<00:02, 33.53it/s]Node 05a08dbc-0c8a-4cb6-bf65-ef55a0bf9ec7 does not have a summary. Skipping filtering.\n",
            "Node be62c310-9b95-4554-b14f-bee8d97d644c does not have a summary. Skipping filtering.\n",
            "Node c31ed9ae-1694-45ca-b188-41fb8177371c does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:01<00:03, 19.55it/s]Node 6b073c1a-2b90-4722-a85e-fb8cc51c400e does not have a summary. Skipping filtering.\n",
            "Node 70515ef7-bf9e-43c5-a57d-4f12449c41f5 does not have a summary. Skipping filtering.\n",
            "Node d5922f0d-2e80-495b-800e-29f6ebed1d64 does not have a summary. Skipping filtering.\n",
            "Node 2aa1557b-2992-4c2e-9843-9e014ebc49ea does not have a summary. Skipping filtering.\n",
            "Node 77885883-d920-43e1-b6de-4cdf975a65b2 does not have a summary. Skipping filtering.\n",
            "Node 37d34f11-68b3-4b4f-b8b1-6bc3deff98ab does not have a summary. Skipping filtering.\n",
            "Node a0c1ea0c-9163-417c-870e-f7ac4d3dece4 does not have a summary. Skipping filtering.\n",
            "Node 54b4fd87-05e3-473c-9d87-92e7429b4bdc does not have a summary. Skipping filtering.\n",
            "Node 2f645336-1c4f-47ae-bf4d-811333ca0500 does not have a summary. Skipping filtering.\n",
            "Node 1ed61ad2-bf14-4800-8e36-8f841768db4a does not have a summary. Skipping filtering.\n",
            "Node 3dd5c7f4-a7cd-4003-b857-df2611d4eda1 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse QuestionPotentialOutput from completion \"{\\\"score\\\": 4}\". Got: 1 validation error for QuestionPotentialOutput\n",
            "  Input should be a valid dictionary or instance of QuestionPotentialOutput [type=model_type, input_value='{\"score\": 4}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:01<00:01, 37.76it/s]unable to apply transformation: Failed to parse QuestionPotentialOutput from completion \"{\\\"score\\\": 5}\". Got: 1 validation error for QuestionPotentialOutput\n",
            "  Input should be a valid dictionary or instance of QuestionPotentialOutput [type=model_type, input_value='{\"score\": 5}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Node c08d527f-c519-43c6-b26a-0dc01c76839d does not have a summary. Skipping filtering.\n",
            "Node 3e0e1499-aecd-4a95-9a21-ad6898b9a4a8 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse QuestionPotentialOutput from completion \"{\\\"score\\\": 5}\". Got: 1 validation error for QuestionPotentialOutput\n",
            "  Input should be a valid dictionary or instance of QuestionPotentialOutput [type=model_type, input_value='{\"score\": 5}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Node 2892aa3f-010e-450b-8c9e-6efe7c6b583c does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:01<00:01, 37.04it/s]Node 64d39142-4b5b-406c-ac67-360382b9baab does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse QuestionPotentialOutput from completion \"{\\\"score\\\": 5}\". Got: 1 validation error for QuestionPotentialOutput\n",
            "  Input should be a valid dictionary or instance of QuestionPotentialOutput [type=model_type, input_value='{\"score\": 5}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Node 3f8470d3-3cbe-4ce0-a385-d783e61eb223 does not have a summary. Skipping filtering.\n",
            "Node cae220c2-8c73-4638-8c65-768a8ed95552 does not have a summary. Skipping filtering.\n",
            "Node 4a0a0c22-6eba-4453-ac7f-8d6676ea01a8 does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 63/100 [00:01<00:00, 39.25it/s]Node 2fa063cf-2a10-4977-b605-d38d65c57753 does not have a summary. Skipping filtering.\n",
            "Node ddaaa196-6061-46d3-9a0d-2b231fb7b68e does not have a summary. Skipping filtering.\n",
            "Node 0b437836-b407-492d-9a1e-a88577134465 does not have a summary. Skipping filtering.\n",
            "Node b81e0e06-04ea-4539-8136-7019b1f1fbf2 does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 68/100 [00:02<00:00, 40.64it/s]Node c362bdd5-8a92-4607-a52c-fe1f39f1042a does not have a summary. Skipping filtering.\n",
            "Node 92d9c683-57c9-4395-8d87-9d6c6d45fbf4 does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:02<00:00, 34.17it/s]Node 14fc2194-2bc9-4ff6-a2bb-806cf215e771 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse QuestionPotentialOutput from completion \"{\\\"score\\\": 5}\". Got: 1 validation error for QuestionPotentialOutput\n",
            "  Input should be a valid dictionary or instance of QuestionPotentialOutput [type=model_type, input_value='{\"score\": 5}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Node fbbd0172-b828-4037-85cf-11a291ea4491 does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 78/100 [00:02<00:00, 25.30it/s]unable to apply transformation: Failed to parse QuestionPotentialOutput from completion \"{\\\"score\\\": 4}\". Got: 1 validation error for QuestionPotentialOutput\n",
            "  Input should be a valid dictionary or instance of QuestionPotentialOutput [type=model_type, input_value='{\"score\": 4}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Node ec576b03-8c9f-4fa6-9e09-5d040b50b0da does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [00:03<00:01, 15.00it/s]Node df548c59-12dd-4f86-863b-438b14d64087 does not have a summary. Skipping filtering.\n",
            "Applying CustomNodeFilter:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:03<00:00, 15.85it/s]unable to apply transformation: Failed to parse QuestionPotentialOutput from completion \"{\\\"score\\\": 5}\". Got: 1 validation error for QuestionPotentialOutput\n",
            "  Input should be a valid dictionary or instance of QuestionPotentialOutput [type=model_type, input_value='{\"score\": 5}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:03<00:00, 16.84it/s]Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "unable to apply transformation: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "unable to apply transformation: The output parser failed to parse the output including retries.\n",
            "Applying CustomNodeFilter:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:04<00:00,  9.38it/s]unable to apply transformation: Failed to parse QuestionPotentialOutput from completion \"{\\\"score\\\": 5}\". Got: 1 validation error for QuestionPotentialOutput\n",
            "  Input should be a valid dictionary or instance of QuestionPotentialOutput [type=model_type, input_value='{\"score\": 5}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "unable to apply transformation: The output parser failed to parse the output including retries.\n",
            "Applying CustomNodeFilter:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:05<00:01,  6.34it/s]unable to apply transformation: Failed to parse StringIO from completion \"{\\\"score\\\": 5}\". Got: 1 validation error for StringIO\n",
            "  Input should be a valid dictionary or instance of StringIO [type=model_type, input_value='{\"score\": 5}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "unable to apply transformation: The output parser failed to parse the output including retries.\n",
            "Applying CustomNodeFilter:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [00:05<00:00,  5.54it/s]Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "unable to apply transformation: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "unable to apply transformation: The output parser failed to parse the output including retries.\n",
            "Applying CustomNodeFilter:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:05<00:00,  6.35it/s]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt fix_output_format failed to parse output: The output parser failed to parse the output including retries.\n",
            "Prompt question_potential_prompt failed to parse output: The output parser failed to parse the output including retries.\n",
            "unable to apply transformation: The output parser failed to parse the output including retries.\n",
            "Applying CustomNodeFilter:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [00:06<00:00,  3.99it/s]unable to apply transformation: Failed to parse StringIO from completion \"{\\\"score\\\": 5}\". Got: 1 validation error for StringIO\n",
            "  Input should be a valid dictionary or instance of StringIO [type=model_type, input_value='{\"score\": 5}', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/model_type\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Generating personas: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.71it/s]                                             \n",
            "Generating Scenarios: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.26s/it]\n",
            "Generating Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.93it/s]\n"
          ]
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(documents, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing naive retrieval with ragas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "for test_row in dataset:\n",
        "  response = naive_retrieval_chain.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"].content\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import EvaluationDataset\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [06:35<00:00,  6.59s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.8750, 'faithfulness': 0.7710, 'factual_correctness': 0.4390, 'answer_relevancy': 0.8672, 'context_entity_recall': 0.6625, 'noise_sensitivity_relevant': 0.3172}"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "from ragas.cost import get_token_usage_for_openai\n",
        "\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config,\n",
        "    token_usage_parser=get_token_usage_for_openai,\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TokenUsage(input_tokens=367788, output_tokens=81215, model='')"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.total_tokens()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate bm25 retrieval with ragas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Applying CustomNodeFilter:   0%|          | 0/100 [00:00<?, ?it/s]        Node 5fb08da3-58b3-480f-ad99-54c6516f4358 does not have a summary. Skipping filtering.\n",
            "Node 82875d90-ef4e-4fa8-be37-a6ece4e9045f does not have a summary. Skipping filtering.\n",
            "Node 6dc20355-4eb2-4f9b-95f1-4c223aa5817f does not have a summary. Skipping filtering.\n",
            "Node 8276dfba-aa6c-41fd-887a-d05d830f6183 does not have a summary. Skipping filtering.\n",
            "Node 03ada8ee-5d2f-4358-9715-d93b761913f4 does not have a summary. Skipping filtering.\n",
            "Node 42ed666f-f22c-40fa-bde8-0a9f44db76d5 does not have a summary. Skipping filtering.\n",
            "Node ff5da19c-b015-422c-bc24-feab3a2232bd does not have a summary. Skipping filtering.\n",
            "Node f5ee8aef-3a3b-4389-8a69-c306024b4ddb does not have a summary. Skipping filtering.\n",
            "Node 21e1c5c2-55cf-4cd2-a3f9-3e23eaeb900b does not have a summary. Skipping filtering.\n",
            "Node ed5b3489-4b1c-4f2f-933c-05ab3f3a2c20 does not have a summary. Skipping filtering.\n",
            "Node 549fadab-ec8b-4292-bc75-620121d7f901 does not have a summary. Skipping filtering.\n",
            "Node 8a90e4b2-fccd-4587-a685-3ff32c26b70f does not have a summary. Skipping filtering.\n",
            "Node 10da8c3f-c8b2-4508-9122-593b2391b4c5 does not have a summary. Skipping filtering.\n",
            "Node 0d26dcce-13bc-4adc-a365-4b10788af56e does not have a summary. Skipping filtering.\n",
            "Node 129c96cf-42a2-4feb-b23c-90a1a67899ec does not have a summary. Skipping filtering.\n",
            "Node 346b8a5a-1632-4e52-bc77-d0185bd63351 does not have a summary. Skipping filtering.\n",
            "Node 48ad484f-e8f2-48fb-adc2-f17f91038d12 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  17%|â–ˆâ–‹        | 17/100 [00:02<00:11,  6.96it/s]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  19%|â–ˆâ–‰        | 19/100 [00:02<00:12,  6.62it/s]Node 8666500b-0010-4131-822a-0ddf2cbfc4c5 does not have a summary. Skipping filtering.\n",
            "Node 9a9c5612-6885-4550-9650-2dd5fa1a312e does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  20%|â–ˆâ–ˆ        | 20/100 [00:03<00:16,  4.82it/s]Node c17ffc69-0344-4aad-8072-f26ad2d4e2f4 does not have a summary. Skipping filtering.\n",
            "Node 3bc2bb99-e8f8-422f-ad4b-2fa5042d4dc3 does not have a summary. Skipping filtering.\n",
            "Node d65ddd78-7f5f-45dc-b47d-8ce6f76d4794 does not have a summary. Skipping filtering.\n",
            "Node 15ff9429-447c-40d8-9002-772013ef37fb does not have a summary. Skipping filtering.\n",
            "Node 6a1ae4df-c75e-4de5-a1cb-ceec34a345e3 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  27%|â–ˆâ–ˆâ–‹       | 27/100 [00:11<00:47,  1.53it/s]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  29%|â–ˆâ–ˆâ–‰       | 29/100 [00:17<01:11,  1.01s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  30%|â–ˆâ–ˆâ–ˆ       | 30/100 [00:22<01:40,  1.44s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:28<02:19,  2.02s/it]Node 24a2cfb1-4251-416c-9157-8ce1b6e571d1 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  32%|â–ˆâ–ˆâ–ˆâ–      | 32/100 [00:33<02:55,  2.58s/it]Node 04b72ee2-94fb-4a50-aa53-dd9f08b6c7b6 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:38<02:50,  2.58s/it]Node 74441b13-06a8-4e4e-8c59-4a2350570a09 does not have a summary. Skipping filtering.\n",
            "Node c88b1fef-ef4f-4272-9b3d-c536831fc989 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 36/100 [00:44<02:47,  2.62s/it]Node 71e355bd-50f8-4910-9d53-a62823f32d21 does not have a summary. Skipping filtering.\n",
            "Node 89395b59-56e6-4302-b745-a032219fdd9b does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 39/100 [00:49<02:19,  2.29s/it]Node 77a79d22-c9d9-4915-95d9-914a0b74c60c does not have a summary. Skipping filtering.\n",
            "Node d1c44cb6-e16e-4260-9f28-1c623d96fa96 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/100 [00:55<02:03,  2.13s/it]Node 64a03365-d3cb-4bc8-8347-f69b6c36cc14 does not have a summary. Skipping filtering.\n",
            "Node 7bdeb8e6-74ff-4864-afe8-2b3ba69b6224 does not have a summary. Skipping filtering.\n",
            "Node 417adf89-6553-4818-8eda-6fb1facd5fc9 does not have a summary. Skipping filtering.\n",
            "Node 52f29050-804b-4153-88d7-4d8393ce5013 does not have a summary. Skipping filtering.\n",
            "Node 974992e2-0b25-4959-99be-b6b44b07b856 does not have a summary. Skipping filtering.\n",
            "Node 7f9f4e84-9c76-4b84-bf94-13638a0c4861 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 51/100 [01:00<00:59,  1.21s/it]Node 597ccf62-c8c4-42fd-9d5f-724ddee54186 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [01:06<01:14,  1.56s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [01:12<01:25,  1.86s/it]Node 4f348531-9f6e-41ed-a752-9ba1c776ff1b does not have a summary. Skipping filtering.\n",
            "Node 17e8cdac-cf50-4a6f-b2a3-ea4cf9aacfe4 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [01:17<01:43,  2.29s/it]Node 8e633649-ef1f-4e0d-9535-dfd170635ab2 does not have a summary. Skipping filtering.\n",
            "Node 874f50b5-66fe-4463-a3cd-c585776c0b5c does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [01:23<01:21,  1.98s/it]Node fca5cfa3-cab1-4991-b202-62feefb1de07 does not have a summary. Skipping filtering.\n",
            "Node 61422006-86b4-403c-9572-be07a8309c66 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [01:29<01:23,  2.15s/it]Node a7ccd317-f23d-4f5d-aa02-e661d5a3e5b8 does not have a summary. Skipping filtering.\n",
            "Node 592104f2-2039-49ed-ae47-4104d4472241 does not have a summary. Skipping filtering.\n",
            "Node cc652b72-0e2b-4d93-aa9e-d5b7730e0546 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-CCzvZht4jybni0eR1HCoQpko on tokens per min (TPM): Limit 80000, Used 77350, Requested 3834. Please try again in 888ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Applying CustomNodeFilter:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 65/100 [01:30<00:49,  1.42s/it]Node fa94cf7c-ce9a-4f80-a529-ee7e0904cd49 does not have a summary. Skipping filtering.\n",
            "Node 0ce23dc8-689a-4b71-b0b3-0028a6879402 does not have a summary. Skipping filtering.\n",
            "Node e4d7969a-bbc2-4d54-a7d8-24c8af0a50f1 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [01:37<00:42,  1.42s/it]Node f4190d32-9239-46e6-b2d5-6af5eee8095b does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 72/100 [01:42<00:45,  1.61s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/100 [01:47<00:48,  1.88s/it]Node e640cb9f-13a4-4e74-aa44-ae56a090c2fa does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 75/100 [01:53<00:59,  2.38s/it]Node 5aea2003-74ba-4857-ab17-e78d3c82a0f6 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 77/100 [02:00<01:00,  2.62s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [02:05<00:54,  2.58s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [02:09<00:58,  2.92s/it]Node f995e27b-1702-414f-9269-eb57253a7c65 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [02:15<01:05,  3.43s/it]Node 9bc86160-27b9-44ab-ba80-b16d72767855 does not have a summary. Skipping filtering.\n",
            "unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-CCzvZht4jybni0eR1HCoQpko on tokens per min (TPM): Limit 80000, Used 79584, Requested 4117. Please try again in 2.775s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Applying CustomNodeFilter:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 83/100 [02:17<00:43,  2.56s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-CCzvZht4jybni0eR1HCoQpko on tokens per min (TPM): Limit 80000, Used 78091, Requested 3905. Please try again in 1.497s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Applying CustomNodeFilter:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [02:20<00:34,  2.31s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 86/100 [02:22<00:32,  2.29s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 87/100 [02:26<00:32,  2.48s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [02:28<00:29,  2.46s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-CCzvZht4jybni0eR1HCoQpko on tokens per min (TPM): Limit 80000, Used 79473, Requested 4023. Please try again in 2.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "Applying CustomNodeFilter:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 89/100 [02:30<00:26,  2.40s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4 in organization org-CCzvZht4jybni0eR1HCoQpko on tokens per min (TPM): Limit 80000, Used 79385, Requested 3938. Please try again in 2.492s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [02:31<00:13,  1.51s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 92/100 [02:34<00:15,  1.94s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [02:39<00:19,  2.75s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [02:42<00:16,  2.75s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 4}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 4}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 95/100 [02:53<00:25,  5.06s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 96/100 [02:54<00:15,  3.95s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [02:57<00:10,  3.64s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 98/100 [03:00<00:06,  3.32s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Applying CustomNodeFilter:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 99/100 [03:06<00:04,  4.21s/it]unable to apply transformation: Failed to parse StringIO from completion {\"score\": 5}. Got: 1 validation error for StringIO\n",
            "text\n",
            "  Field required [type=missing, input_value={'score': 5}, input_type=dict]\n",
            "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
            "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
            "Generating personas: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.27it/s]                                             \n",
            "Generating Scenarios: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:16<00:00,  8.00s/it]\n",
            "Generating Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:05<00:00,  1.82it/s]\n",
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 60/60 [03:49<00:00,  3.82s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.7700, 'faithfulness': 0.6618, 'factual_correctness': 0.4140, 'answer_relevancy': 0.6647, 'context_entity_recall': 0.6861, 'noise_sensitivity_relevant': 0.2708}"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(documents, testset_size=10)\n",
        "\n",
        "dataset.to_pandas()\n",
        "\n",
        "for test_row in dataset:\n",
        "  response = bm25_retrieval_chain.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"].content\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "  \n",
        "from ragas import EvaluationDataset\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "\n",
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "\n",
        "\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "from ragas.cost import get_token_usage_for_openai\n",
        "\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config,\n",
        "    token_usage_parser=get_token_usage_for_openai,\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TokenUsage(input_tokens=213266, output_tokens=67759, model='')"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.total_tokens()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate contextual compression with ragas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : evaluator_llm})\n",
        "\n",
        "\n",
        "def prepare_data(run, example):\n",
        "    # Handle AIMessage output\n",
        "    if isinstance(run.outputs, dict):\n",
        "        if \"response\" in run.outputs:\n",
        "            prediction = run.outputs[\"response\"].content\n",
        "        else:\n",
        "            prediction = str(run.outputs)\n",
        "    else:\n",
        "        # Direct AIMessage\n",
        "        prediction = run.outputs.content\n",
        "    \n",
        "    return {\n",
        "        \"prediction\": prediction,              # Required by StringEvaluator\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "        # Keep these for qa_evaluator\n",
        "        \"query\": example.inputs[\"question\"],\n",
        "        \"result\": prediction,\n",
        "        \"answer\": example.outputs[\"answer\"]\n",
        "    }\n",
        "\n",
        "\n",
        "# Create evaluators with updated prepare_data\n",
        "qa_evaluator = LangChainStringEvaluator(\n",
        "    \"qa\", \n",
        "    config={\"llm\": evaluator_llm},\n",
        "    prepare_data=prepare_data\n",
        ")\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": \"Is this submission helpful to the user?\"\n",
        "        },\n",
        "        \"llm\": evaluator_llm\n",
        "    },\n",
        "    prepare_data=prepare_data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Applying SummaryExtractor:   0%|          | 0/44 [00:00<?, ?it/s]Task exception was never retrieved\n",
            "future: <Task finished name='Task-19211' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19197' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19212' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19213' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19199' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19201' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19203' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19204' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19205' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19206' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19207' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19208' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19209' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-19210' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25406' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25392' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25407' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25393' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25379' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25408' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25394' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25380' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25409' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25395' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25381' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25410' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25396' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25382' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25411' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25397' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25383' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25412' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25398' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25384' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25413' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25399' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25385' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25414' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25400' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25386' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25415' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25401' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25387' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25416' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25402' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25388' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25403' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25389' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25376' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25404' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25390' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25405' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Task exception was never retrieved\n",
            "future: <Task finished name='Task-25391' coro=<as_completed.<locals>.sema_coro() done, defined at /Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py:46> exception=RateLimitError(\"Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\")>\n",
            "Traceback (most recent call last):\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/executor.py\", line 48, in sema_coro\n",
            "    return await coro\n",
            "           ^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/base.py\", line 178, in apply_extract\n",
            "    property_name, property_value = await self.extract(node)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/extractors/llm_based.py\", line 180, in extract\n",
            "    result = await self.prompt.generate(self.llm, data=StringIO(text=chunks[0]))\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 129, in generate\n",
            "    output_single = await self.generate_multiple(\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<7 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/prompt/pydantic_prompt.py\", line 190, in generate_multiple\n",
            "    resp = await llm.generate(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 108, in generate\n",
            "    result = await agenerate_text_with_retry(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 189, in async_wrapped\n",
            "    return await copy(fn, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 111, in __call__\n",
            "    do = await self.iter(retry_state=retry_state)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 153, in iter\n",
            "    result = await action(retry_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/_utils.py\", line 99, in inner\n",
            "    return call(*args, **kwargs)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 418, in exc_check\n",
            "    raise retry_exc.reraise()\n",
            "          ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 185, in reraise\n",
            "    raise self.last_attempt.result()\n",
            "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n",
            "    return self.__get_result()\n",
            "           ~~~~~~~~~~~~~~~~~^^\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/tenacity/asyncio/__init__.py\", line 114, in __call__\n",
            "    result = await fn(*args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/llms/base.py\", line 253, in agenerate_text\n",
            "    result = await self.langchain_llm.agenerate_prompt(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<3 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 870, in agenerate_prompt\n",
            "    return await self.agenerate(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "        prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 830, in agenerate\n",
            "    raise exceptions[0]\n",
            "  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/asyncio/tasks.py\", line 304, in __step_run_and_handle_result\n",
            "    result = coro.send(None)\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py\", line 998, in _agenerate_with_cache\n",
            "    result = await self._agenerate(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^\n",
            "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py\", line 970, in _agenerate\n",
            "    response = await self.async_client.create(**payload)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n",
            "    return await self._post(\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "    ...<42 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1862, in post\n",
            "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1556, in request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1642, in _request\n",
            "    return await self._retry_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<6 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1689, in _retry_request\n",
            "    return await self._request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "    ...<5 lines>...\n",
            "    )\n",
            "    ^\n",
            "  File \"/Users/walidkoleilat/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/openai/_base_client.py\", line 1657, in _request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:   2%|â–         | 1/44 [01:40<1:12:02, 100.51s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:   5%|â–         | 2/44 [01:54<34:55, 49.89s/it]   unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:   7%|â–‹         | 3/44 [02:06<22:09, 32.42s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:   9%|â–‰         | 4/44 [02:09<13:45, 20.63s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  11%|â–ˆâ–        | 5/44 [02:10<08:52, 13.65s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  14%|â–ˆâ–Ž        | 6/44 [02:11<05:58,  9.44s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  16%|â–ˆâ–Œ        | 7/44 [02:14<04:24,  7.15s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  18%|â–ˆâ–Š        | 8/44 [02:14<03:00,  5.02s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  20%|â–ˆâ–ˆ        | 9/44 [02:16<02:24,  4.13s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  23%|â–ˆâ–ˆâ–Ž       | 10/44 [02:20<02:17,  4.05s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  25%|â–ˆâ–ˆâ–Œ       | 11/44 [02:21<01:38,  2.99s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  27%|â–ˆâ–ˆâ–‹       | 12/44 [02:24<01:33,  2.94s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  30%|â–ˆâ–ˆâ–‰       | 13/44 [02:43<04:06,  7.94s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  32%|â–ˆâ–ˆâ–ˆâ–      | 14/44 [02:46<03:16,  6.54s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  34%|â–ˆâ–ˆâ–ˆâ–      | 15/44 [03:20<07:06, 14.72s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 17/44 [03:36<05:12, 11.56s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/44 [03:59<06:16, 14.48s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 19/44 [04:03<04:51, 11.67s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 20/44 [04:03<03:26,  8.59s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 21/44 [04:04<02:24,  6.29s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 22/44 [04:05<01:46,  4.83s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 23/44 [04:08<01:34,  4.49s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/44 [04:13<01:29,  4.48s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 25/44 [04:15<01:13,  3.85s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 26/44 [04:20<01:14,  4.12s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 28/44 [04:41<01:53,  7.11s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 29/44 [04:51<01:56,  7.79s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 30/44 [05:14<02:44, 11.74s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 31/44 [05:15<01:54,  8.82s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 32/44 [05:22<01:38,  8.24s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 33/44 [05:25<01:14,  6.79s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 34/44 [05:58<02:25, 14.52s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 35/44 [06:04<01:47, 11.98s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 36/44 [06:08<01:17,  9.63s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/44 [06:09<00:50,  7.15s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 38/44 [06:18<00:45,  7.51s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 39/44 [06:19<00:27,  5.49s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 40/44 [06:19<00:16,  4.04s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 41/44 [06:28<00:16,  5.41s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "Applying SummaryExtractor:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 42/44 [06:51<00:21, 10.79s/it]unable to apply transformation: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
            "                                                                          \r"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[108]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m generator_embeddings = LangchainEmbeddingsWrapper(embeddings=base_embeddings)\n\u001b[32m     11\u001b[39m generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m dataset = \u001b[43mgenerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_with_langchain_docs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m dataset.to_pandas()\n\u001b[32m     16\u001b[39m dataset_contextual = dataset.copy()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/synthesizers/generate.py:185\u001b[39m, in \u001b[36mTestsetGenerator.generate_with_langchain_docs\u001b[39m\u001b[34m(self, documents, testset_size, transforms, transforms_llm, transforms_embedding_model, query_distribution, run_config, callbacks, with_debugging_logs, raise_exceptions)\u001b[39m\n\u001b[32m    182\u001b[39m kg = KnowledgeGraph(nodes=nodes)\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# apply transforms and update the knowledge graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[43mapply_transforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28mself\u001b[39m.knowledge_graph = kg\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.generate(\n\u001b[32m    189\u001b[39m     testset_size=testset_size,\n\u001b[32m    190\u001b[39m     query_distribution=query_distribution,\n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m     raise_exceptions=raise_exceptions,\n\u001b[32m    195\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/ragas/testset/transforms/engine.py:106\u001b[39m, in \u001b[36mapply_transforms\u001b[39m\u001b[34m(kg, transforms, run_config, callbacks)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transforms, t.List):\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m transform \u001b[38;5;129;01min\u001b[39;00m transforms:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m         \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_coroutines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_execution_plan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m                \u001b[49m\u001b[43mget_desc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# if Parallel, collect inside it and run it all\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transforms, Parallel):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/nest_asyncio.py:30\u001b[39m, in \u001b[36m_patch_asyncio.<locals>.run\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m     28\u001b[39m task = asyncio.ensure_future(main)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task.done():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/aie5-repos-v2/13_Advanced_Retrieval/.venv/lib/python3.13/site-packages/nest_asyncio.py:115\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     heappop(scheduled)\n\u001b[32m    110\u001b[39m timeout = (\n\u001b[32m    111\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    113\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    118\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py:548\u001b[39m, in \u001b[36mKqueueSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    546\u001b[39m ready = []\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     kev_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    550\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "# Create the base models\n",
        "base_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "base_embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Wrap them for ragas\n",
        "generator_llm = LangchainLLMWrapper(langchain_llm=base_llm)\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(embeddings=base_embeddings)\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(documents, testset_size=10)\n",
        "\n",
        "dataset.to_pandas()\n",
        "\n",
        "dataset_contextual = dataset.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : evaluator_llm})\n",
        "\n",
        "\n",
        "def prepare_data(run, example):\n",
        "    # Handle AIMessage output\n",
        "    if isinstance(run.outputs, dict):\n",
        "        if \"response\" in run.outputs:\n",
        "            prediction = run.outputs[\"response\"].content\n",
        "        else:\n",
        "            prediction = str(run.outputs)\n",
        "    else:\n",
        "        # Direct AIMessage\n",
        "        prediction = run.outputs.content\n",
        "    \n",
        "    return {\n",
        "        \"prediction\": prediction,              # Required by StringEvaluator\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "        # Keep these for qa_evaluator\n",
        "        \"query\": example.inputs[\"question\"],\n",
        "        \"result\": prediction,\n",
        "        \"answer\": example.outputs[\"answer\"]\n",
        "    }\n",
        "\n",
        "\n",
        "# Create evaluators with updated prepare_data\n",
        "qa_evaluator = LangChainStringEvaluator(\n",
        "    \"qa\", \n",
        "    config={\"llm\": evaluator_llm},\n",
        "    prepare_data=prepare_data\n",
        ")\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": \"Is this submission helpful to the user?\"\n",
        "        },\n",
        "        \"llm\": evaluator_llm\n",
        "    },\n",
        "    prepare_data=prepare_data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : evaluator_llm})\n",
        "\n",
        "\n",
        "def prepare_data(run, example):\n",
        "    # Handle AIMessage output\n",
        "    if isinstance(run.outputs, dict):\n",
        "        if \"response\" in run.outputs:\n",
        "            prediction = run.outputs[\"response\"].content\n",
        "        else:\n",
        "            prediction = str(run.outputs)\n",
        "    else:\n",
        "        # Direct AIMessage\n",
        "        prediction = run.outputs.content\n",
        "    \n",
        "    return {\n",
        "        \"prediction\": prediction,              # Required by StringEvaluator\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "        # Keep these for qa_evaluator\n",
        "        \"query\": example.inputs[\"question\"],\n",
        "        \"result\": prediction,\n",
        "        \"answer\": example.outputs[\"answer\"]\n",
        "    }\n",
        "\n",
        "\n",
        "# Create evaluators with updated prepare_data\n",
        "qa_evaluator = LangChainStringEvaluator(\n",
        "    \"qa\", \n",
        "    config={\"llm\": evaluator_llm},\n",
        "    prepare_data=prepare_data\n",
        ")\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": \"Is this submission helpful to the user?\"\n",
        "        },\n",
        "        \"llm\": evaluator_llm\n",
        "    },\n",
        "    prepare_data=prepare_data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : evaluator_llm})\n",
        "\n",
        "\n",
        "def prepare_data(run, example):\n",
        "    # Handle AIMessage output\n",
        "    if isinstance(run.outputs, dict):\n",
        "        if \"response\" in run.outputs:\n",
        "            prediction = run.outputs[\"response\"].content\n",
        "        else:\n",
        "            prediction = str(run.outputs)\n",
        "    else:\n",
        "        # Direct AIMessage\n",
        "        prediction = run.outputs.content\n",
        "    \n",
        "    return {\n",
        "        \"prediction\": prediction,              # Required by StringEvaluator\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "        # Keep these for qa_evaluator\n",
        "        \"query\": example.inputs[\"question\"],\n",
        "        \"result\": prediction,\n",
        "        \"answer\": example.outputs[\"answer\"]\n",
        "    }\n",
        "\n",
        "\n",
        "# Create evaluators with updated prepare_data\n",
        "qa_evaluator = LangChainStringEvaluator(\n",
        "    \"qa\", \n",
        "    config={\"llm\": evaluator_llm},\n",
        "    prepare_data=prepare_data\n",
        ")\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": \"Is this submission helpful to the user?\"\n",
        "        },\n",
        "        \"llm\": evaluator_llm\n",
        "    },\n",
        "    prepare_data=prepare_data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : evaluator_llm})\n",
        "\n",
        "\n",
        "def prepare_data(run, example):\n",
        "    # Handle AIMessage output\n",
        "    if isinstance(run.outputs, dict):\n",
        "        if \"response\" in run.outputs:\n",
        "            prediction = run.outputs[\"response\"].content\n",
        "        else:\n",
        "            prediction = str(run.outputs)\n",
        "    else:\n",
        "        # Direct AIMessage\n",
        "        prediction = run.outputs.content\n",
        "    \n",
        "    return {\n",
        "        \"prediction\": prediction,              # Required by StringEvaluator\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "        # Keep these for qa_evaluator\n",
        "        \"query\": example.inputs[\"question\"],\n",
        "        \"result\": prediction,\n",
        "        \"answer\": example.outputs[\"answer\"]\n",
        "    }\n",
        "\n",
        "\n",
        "# Create evaluators with updated prepare_data\n",
        "qa_evaluator = LangChainStringEvaluator(\n",
        "    \"qa\", \n",
        "    config={\"llm\": evaluator_llm},\n",
        "    prepare_data=prepare_data\n",
        ")\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": \"Is this submission helpful to the user?\"\n",
        "        },\n",
        "        \"llm\": evaluator_llm\n",
        "    },\n",
        "    prepare_data=prepare_data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for test_row in dataset_contextual:\n",
        "  response = naive_retrieval_chain.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"].content\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "  \n",
        "from ragas import EvaluationDataset\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())\n",
        "\n",
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
        "\n",
        "\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "from ragas.cost import get_token_usage_for_openai\n",
        "\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config,\n",
        "    token_usage_parser=get_token_usage_for_openai,\n",
        ")\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "** I also tried to use LangSmith to evaluate the retrievers and used their instructions to evaluate RAGs. I used the following code to evaluate the retrievers: **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
        "#os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client(api_key=os.environ[\"LANGSMITH_API_KEY\"])\n",
        "\n",
        "dataset_name = \"John Wick Retrieval v3\"\n",
        "\n",
        "langsmith_dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"John Wick Retrieval\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "for data_row in dataset.to_pandas().iterrows():\n",
        "  client.create_example(\n",
        "      inputs={\n",
        "          \"question\": data_row[1][\"user_input\"]\n",
        "      },\n",
        "      outputs={\n",
        "          \"answer\": data_row[1][\"reference\"]\n",
        "      },\n",
        "      metadata={\n",
        "          \"context\": data_row[1][\"reference_contexts\"]\n",
        "      },\n",
        "      dataset_id=langsmith_dataset.id\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Correctness: Reponse vs Reference Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "# Grade output schema\n",
        "class CorrectnessGrade(TypedDict):\n",
        "    # Note that the order in the fields are defined is the order in which the model will generate them.\n",
        "    # It is useful to put explanations before responses because it forces the model to think through\n",
        "    # its final response before generating it:\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    correct: Annotated[bool, ..., \"True if the answer is correct, False otherwise.\"]\n",
        "\n",
        "# Grade prompt\n",
        "correctness_instructions = \"\"\"You are a teacher grading a quiz. \n",
        "\n",
        "You will be given a QUESTION, the GROUND TRUTH (correct) ANSWER, and the STUDENT ANSWER. \n",
        "\n",
        "Here is the grade criteria to follow:\n",
        "(1) Grade the student answers based ONLY on their factual accuracy relative to the ground truth answer. \n",
        "(2) Ensure that the student answer does not contain any conflicting statements.\n",
        "(3) It is OK if the student answer contains more information than the ground truth answer, as long as it is factually accurate relative to the  ground truth answer.\n",
        "\n",
        "Correctness:\n",
        "A correctness value of True means that the student's answer meets all of the criteria.\n",
        "A correctness value of False means that the student's answer does not meet all of the criteria.\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
        "\n",
        "Avoid simply stating the correct answer at the outset.\"\"\"\n",
        "\n",
        "# Grader LLM\n",
        "grader_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(CorrectnessGrade, method=\"json_schema\", strict=True)\n",
        "\n",
        "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
        "    \"\"\"An evaluator for RAG answer accuracy\"\"\"\n",
        "    # Get the answer from the response\n",
        "    if isinstance(outputs[\"response\"], dict):\n",
        "        answer = outputs[\"response\"].get(\"content\", \"\")\n",
        "    else:\n",
        "        answer = outputs[\"response\"].content\n",
        "        \n",
        "    answers = f\"\"\"      QUESTION: {inputs['question']}\n",
        "GROUND TRUTH ANSWER: {reference_outputs['answer']}\n",
        "STUDENT ANSWER: {answer}\"\"\"\n",
        "\n",
        "    # Run evaluator\n",
        "    grade = grader_llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": correctness_instructions}, \n",
        "        {\"role\": \"user\", \"content\": answers}\n",
        "    ])\n",
        "    return grade[\"correct\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : evaluator_llm})\n",
        "\n",
        "\n",
        "def prepare_data(run, example):\n",
        "    # Handle AIMessage output\n",
        "    if isinstance(run.outputs, dict):\n",
        "        if \"response\" in run.outputs:\n",
        "            prediction = run.outputs[\"response\"].content\n",
        "        else:\n",
        "            prediction = str(run.outputs)\n",
        "    else:\n",
        "        # Direct AIMessage\n",
        "        prediction = run.outputs.content\n",
        "    \n",
        "    return {\n",
        "        \"prediction\": prediction,              # Required by StringEvaluator\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "        # Keep these for qa_evaluator\n",
        "        \"query\": example.inputs[\"question\"],\n",
        "        \"result\": prediction,\n",
        "        \"answer\": example.outputs[\"answer\"]\n",
        "    }\n",
        "\n",
        "\n",
        "# Create evaluators with updated prepare_data\n",
        "qa_evaluator = LangChainStringEvaluator(\n",
        "    \"qa\", \n",
        "    config={\"llm\": evaluator_llm},\n",
        "    prepare_data=prepare_data\n",
        ")\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": \"Is this submission helpful to the user?\"\n",
        "        },\n",
        "        \"llm\": evaluator_llm\n",
        "    },\n",
        "    prepare_data=prepare_data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Relevance: Response vs Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grade output schema\n",
        "class RelevanceGrade(TypedDict):\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    relevant: Annotated[bool, ..., \"Provide the score on whether the answer addresses the question\"]\n",
        "\n",
        "# Grade prompt\n",
        "relevance_instructions=\"\"\"You are a teacher grading a quiz. \n",
        "\n",
        "You will be given a QUESTION and a STUDENT ANSWER. \n",
        "\n",
        "Here is the grade criteria to follow:\n",
        "(1) Ensure the STUDENT ANSWER is concise and relevant to the QUESTION\n",
        "(2) Ensure the STUDENT ANSWER helps to answer the QUESTION\n",
        "\n",
        "Relevance:\n",
        "A relevance value of True means that the student's answer meets all of the criteria.\n",
        "A relevance value of False means that the student's answer does not meet all of the criteria.\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
        "\n",
        "Avoid simply stating the correct answer at the outset.\"\"\"\n",
        "\n",
        "# Grader LLM\n",
        "relevance_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(RelevanceGrade, method=\"json_schema\", strict=True)\n",
        "\n",
        "# Evaluator\n",
        "def relevance(inputs: dict, outputs: dict) -> bool:\n",
        "    \"\"\"A simple evaluator for RAG answer helpfulness.\"\"\"\n",
        "    # Get the answer from the response\n",
        "    if isinstance(outputs[\"response\"], dict):\n",
        "        answer = outputs[\"response\"].get(\"content\", \"\")\n",
        "    else:\n",
        "        answer = outputs[\"response\"].content\n",
        "    \n",
        "    # Format the input for grading\n",
        "    answer_text = f\"\"\"      QUESTION: {inputs['question']}\n",
        "STUDENT ANSWER: {answer}\"\"\"\n",
        "\n",
        "    # Run evaluator\n",
        "    grade = relevance_llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": relevance_instructions}, \n",
        "        {\"role\": \"user\", \"content\": answer_text}\n",
        "    ])\n",
        "    \n",
        "    return grade[\"relevant\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Groundedness: Response vs Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grade output schema\n",
        "class GroundedGrade(TypedDict):\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    grounded: Annotated[bool, ..., \"Provide the score on if the answer hallucinates from the documents\"]\n",
        "\n",
        "# Grade prompt\n",
        "grounded_instructions = \"\"\"You are a teacher grading a quiz. \n",
        "\n",
        "You will be given FACTS and a STUDENT ANSWER. \n",
        "\n",
        "Here is the grade criteria to follow:\n",
        "(1) Ensure the STUDENT ANSWER is grounded in the FACTS. \n",
        "(2) Ensure the STUDENT ANSWER does not contain \"hallucinated\" information outside the scope of the FACTS.\n",
        "\n",
        "Grounded:\n",
        "A grounded value of True means that the student's answer meets all of the criteria.\n",
        "A grounded value of False means that the student's answer does not meet all of the criteria.\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
        "\n",
        "Avoid simply stating the correct answer at the outset.\"\"\"\n",
        "\n",
        "# Grader LLM \n",
        "grounded_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(GroundedGrade, method=\"json_schema\", strict=True)\n",
        "\n",
        "# Evaluator\n",
        "def groundedness(inputs: dict, outputs: dict) -> bool:\n",
        "    \"\"\"A simple evaluator for RAG answer groundedness.\"\"\"\n",
        "    doc_string = \"\n",
        "\n",
        "\".join(doc.page_content for doc in outputs[\"documents\"])\n",
        "    answer = f\"\"\"      FACTS: {doc_string}\n",
        "STUDENT ANSWER: {outputs['answer']}\"\"\"\n",
        "    grade = grounded_llm.invoke([{\"role\": \"system\", \"content\": grounded_instructions}, {\"role\": \"user\", \"content\": answer}])\n",
        "    return grade[\"grounded\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langsmith.evaluation import LangChainStringEvaluator, evaluate\n",
        "\n",
        "evaluator_llm = ChatOpenAI(model=\"gpt-4\")\n",
        "\n",
        "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : evaluator_llm})\n",
        "\n",
        "\n",
        "def prepare_data(run, example):\n",
        "    # Handle AIMessage output\n",
        "    if isinstance(run.outputs, dict):\n",
        "        if \"response\" in run.outputs:\n",
        "            prediction = run.outputs[\"response\"].content\n",
        "        else:\n",
        "            prediction = str(run.outputs)\n",
        "    else:\n",
        "        # Direct AIMessage\n",
        "        prediction = run.outputs.content\n",
        "    \n",
        "    return {\n",
        "        \"prediction\": prediction,              # Required by StringEvaluator\n",
        "        \"reference\": example.outputs[\"answer\"],\n",
        "        \"input\": example.inputs[\"question\"],\n",
        "        # Keep these for qa_evaluator\n",
        "        \"query\": example.inputs[\"question\"],\n",
        "        \"result\": prediction,\n",
        "        \"answer\": example.outputs[\"answer\"]\n",
        "    }\n",
        "\n",
        "\n",
        "# Create evaluators with updated prepare_data\n",
        "qa_evaluator = LangChainStringEvaluator(\n",
        "    \"qa\", \n",
        "    config={\"llm\": evaluator_llm},\n",
        "    prepare_data=prepare_data\n",
        ")\n",
        "\n",
        "labeled_helpfulness_evaluator = LangChainStringEvaluator(\n",
        "    \"labeled_criteria\",\n",
        "    config={\n",
        "        \"criteria\": {\n",
        "            \"helpfulness\": \"Is this submission helpful to the user?\"\n",
        "        },\n",
        "        \"llm\": evaluator_llm\n",
        "    },\n",
        "    prepare_data=prepare_data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieval Relevance: Retrieved Docs vs Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grade output schema\n",
        "class RetrievalRelevanceGrade(TypedDict):\n",
        "    explanation: Annotated[str, ..., \"Explain your reasoning for the score\"]\n",
        "    relevant: Annotated[bool, ..., \"True if the retrieved documents are relevant to the question, False otherwise\"]\n",
        "\n",
        "# Grade prompt\n",
        "retrieval_relevance_instructions = \"\"\"You are a teacher grading a quiz. \n",
        "\n",
        "You will be given a QUESTION and a set of FACTS provided by the student. \n",
        "\n",
        "Here is the grade criteria to follow:\n",
        "(1) You goal is to identify FACTS that are completely unrelated to the QUESTION\n",
        "(2) If the facts contain ANY keywords or semantic meaning related to the question, consider them relevant\n",
        "(3) It is OK if the facts have SOME information that is unrelated to the question as long as (2) is met\n",
        "\n",
        "Relevance:\n",
        "A relevance value of True means that the FACTS contain ANY keywords or semantic meaning related to the QUESTION and are therefore relevant.\n",
        "A relevance value of False means that the FACTS are completely unrelated to the QUESTION.\n",
        "\n",
        "Explain your reasoning in a step-by-step manner to ensure your reasoning and conclusion are correct. \n",
        "\n",
        "Avoid simply stating the correct answer at the outset.\"\"\"\n",
        "\n",
        "# Grader LLM\n",
        "retrieval_relevance_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0).with_structured_output(RetrievalRelevanceGrade, method=\"json_schema\", strict=True)\n",
        "\n",
        "def retrieval_relevance(inputs: dict, outputs: dict) -> bool:\n",
        "    \"\"\"An evaluator for document relevance\"\"\"\n",
        "    # Join documents with newline\n",
        "    doc_string = \"\\n\".join(doc.page_content for doc in outputs[\"context\"])\n",
        "    \n",
        "    # Format the input for grading\n",
        "    answer_text = f\"\"\"      FACTS: {doc_string}\n",
        "QUESTION: {inputs['question']}\"\"\"\n",
        "\n",
        "    # Run evaluator\n",
        "    grade = retrieval_relevance_llm.invoke([\n",
        "        {\"role\": \"system\", \"content\": retrieval_relevance_instructions}, \n",
        "        {\"role\": \"user\", \"content\": answer_text}\n",
        "    ])\n",
        "    \n",
        "    return grade[\"relevant\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'long-orange-79' at:\n",
            "https://smith.langchain.com/o/306dc215-46b3-4252-a039-f86d8a073560/datasets/32d139e2-4bf0-4ca9-bb48-3caae3f80cf3/compare?selectedSessions=7dfcb96f-2994-4326-9f40-030e3b3d37cd\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "10it [02:06, 12.68s/it]\n"
          ]
        }
      ],
      "source": [
        "from langsmith.evaluation import evaluate as langsmith_evaluate\n",
        "\n",
        "\n",
        "# First read the dataset\n",
        "dataset = client.read_dataset(dataset_name=\"John Wick Retrieval v3\")\n",
        "\n",
        "# Use langsmith_evaluate with the data parameter\n",
        "results = langsmith_evaluate(\n",
        "    naive_retrieval_chain.invoke,\n",
        "    data=\"John Wick Retrieval v3\",  # Use 'data' parameter with dataset name\n",
        "    evaluators=[\n",
        "        correctness, \n",
        "        groundedness, \n",
        "        relevance, \n",
        "        retrieval_relevance\n",
        "    ],\n",
        "    metadata={\"revision_id\": \"john_wick_retrieval_naive\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate contextual compression with ragas.\n",
        "\n",
        "** Did not complete due to hitting quota limit with OpenAI **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate multi-query retrieval with ragas.\n",
        "\n",
        "** Did not complete due to hitting quota limit with OpenAI **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate parent document retrieval with ragas.\n",
        "\n",
        "** Did not complete due to hitting quota limit with OpenAI **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate ensemble retrieval with ragas.\n",
        "\n",
        "** Did not complete due to hitting quota limit with OpenAI **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate semantic chunking with ragas.\n",
        "\n",
        "** Did not complete due to hitting quota limit with OpenAI **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "** Activity 2 Report **\n",
        "\n",
        "I defined new evaluators for the naive retrieval rag chain in langsmith. \n",
        "\n",
        "Here's the result from running a langsmith evaluation on the naive retrieval chain:\n",
        "\n",
        "<div>\n",
        "    <img src=\"image.png\" width=\"1000\">\n",
        "</div>\n",
        "\n",
        "The three evaluators are Correctness, Relevance, and Groundedness.\n",
        "\n",
        "For the naive retrieval chain:\n",
        "\n",
        "- Correctness: 0.7\n",
        "- Groundness: 0.9\n",
        "- Relevance: 0.9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RAGS evaluation of the retrieval approaches.\n",
        "\n",
        "Results for the naive retrieval chain:\n",
        "\n",
        "{'context_recall': 0.8750, 'faithfulness': 0.7710, 'factual_correctness': 0.4390, 'answer_relevancy': 0.8672, 'context_entity_recall': 0.6625, 'noise_sensitivity_relevant': 0.3172}\n",
        "\n",
        "\n",
        "Results for the BM25 retrieval chain:\n",
        "\n",
        "{'context_recall': 0.7700, 'faithfulness': 0.6618, 'factual_correctness': 0.4140, 'answer_relevancy': 0.6647, 'context_entity_recall': 0.6861, 'noise_sensitivity_relevant': 0.2708}\n",
        "\n",
        "\n",
        "| Metric | Naive Retrieval | BM25 Retrieval | % Difference |\n",
        "|--------|----------------|----------------|--------------|\n",
        "| Context Recall | 0.8750 | 0.7700 | +13.64% |\n",
        "| Faithfulness | 0.7710 | 0.6618 | +16.50% |\n",
        "| Factual Correctness | 0.4390 | 0.4140 | +6.04% |\n",
        "| Answer Relevancy | 0.8672 | 0.6647 | +30.46% |\n",
        "| Context Entity Recall | 0.6625 | 0.6861 | -3.44% |\n",
        "| Noise Sensitivity Relevant | 0.3172 | 0.2708 | +17.13% |\n",
        "\n",
        "Analysis of the differences between naive and BM25 retrieval:\n",
        "\n",
        "Context Recall: Naive retrieval has a higher context recall, meaning it is retrieving more relevant pieces of information from the reference data set, which makes sense because it is using semantic similarity to retrieve the relevant pieces of information.\n",
        "\n",
        "Faithfulness: Naive retrieval has a higher faithfulness score, it makes sense since the content retrieved is more relevant to the question.\n",
        "\n",
        "Factual Correctness: It is interesting that naive and BM25 have a close factual correctness score.\n",
        "\n",
        "Answer Relevancy: Naive retrieval has a materially higher answer relevancy score, which makes sense because it is using semantic similarity to retrieve the relevant pieces of information.\n",
        "\n",
        "Context Entity Recall: The difference is not material.\n",
        "\n",
        "Noise Sensitivity Relevant: Naive has higher noise sensitivity and that makes sense because it is using semantic similarity to retrieve the relevant pieces of information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
